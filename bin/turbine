#!/usr/bin/env python
from __future__ import print_function, absolute_import, division
import math
from os.path import split as path_split
from collections import namedtuple
import logging
import argparse

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
try:
    import sklearn
    sklearn_version = tuple(map(int, sklearn.__version__.split('.')))
    if sklearn_version[0] == 0 and sklearn_version[1] < 18:
        exit('Too old sklearn, needs at least 0.18.2, was: %s' %
             sklearn.__version__)
except ImportError as err:
    exit('Failed to import sklearn, have you install scikit learn?\n%s\n' % err)

try:
    from turbinelearn import *
except ImportError as err:
    exit('Failed to import turbinelearn\n%s' % err)


LearningParameter = namedtuple('LearningParameter',
                               ['degree', 'training_fraction', 'k',
                                'dataset', 'clean', 'normalize', 'purge',
                                'dual_model', 'dual_export', 'ridge'])


def get_prediction(params, i):
    """Return (y, prediction) for test data for ith dataset"""
    res = train_and_evaluate_single_file(params.dataset[i],
                                         training_fraction=params.training_fraction,
                                         degree=params.degree,
                                         limits=get_limits(params),
                                         normalize=get_normalize(params),
                                         purge=params.purge,
                                         ridge=params.ridge)
    data, training_data, test_data, reg_mod = res
    X, y = test_data
    predicted = reg_mod.predict(X)
    return y, predicted


def method_prediction(params):
    i = 0
    N = len(params.dataset)
    for input_file in params.dataset:
        y, predicted = get_prediction(params, i)
        fname = path_split(input_file)
        i = i + 1
        if N > 1:
            plt.subplot(math.ceil(N/2.0), 2, i)
        plt.title(fname[1])
        plt.scatter(y, predicted)
        plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=1)
        plt.xlabel('Measured')
        plt.ylabel('Predicted')
    plt.show()


def visualize(data, training_data, test_data, reg_mod):
    data_timeline = data[1].index
    training_data_timeline = training_data[1].index
    test_data_timeline = test_data[1].index

    plt.plot(
        data_timeline, data[1], "ro",
        training_data_timeline, reg_mod.predict(training_data[0]), "bo",
        test_data_timeline, reg_mod.predict(test_data[0]), "go",
        markersize=2)


def create_argparse():
    parser = argparse.ArgumentParser(description='Learns a polynomial.')
    parser.add_argument('-m', '--method', dest='method',
                        choices=['fcv', 'icv', 'simple', 'pca', 'reg', 'progress', 'prediction', 'export'],
                        required=True,
                        help=('Uses either filebased cross validation (fcv), '
                              'individual file cross validation (icv), '
                              'run a single train-test run on each file (simple) '
                              'or do PCA (pca)'))
    parser.add_argument('-d', '--degree', dest='degree', type=int, default=2,
                        help='The degree of the polynomial to train, defaults to 2')

    parser.add_argument('--clean', dest='clean', action='store_true',
                        help='Whether to perform data cleanup (recommended), defaults to --clean.')
    parser.add_argument('--no-clean', dest='clean', action='store_false')
    parser.set_defaults(clean=True)
    parser.add_argument('--normalize', dest='normalize', action='store_true',
                        help='Whether to perform data normalization (not needed for polynomial model), defaults to --no-normalize.')
    parser.add_argument('--no-normalize', dest='normalize', action='store_false')
    parser.set_defaults(normalize=False)
    parser.add_argument('-p', '--purge', dest='purge', type=float, default=0,
                        help='Purge small coefficients from exported polynomial.')

    parser.add_argument('-t', '--training-fraction', dest='training_fraction', type=float, default=0.6,
                        help='The fraction of data to use as training data, only used when method=simple')
    parser.add_argument('-k', '--k', dest='k', type=int, default=2,
                        help=('The number of folds to keep out when using cross validation.  '
                              'For method=fcv it is the number of files to keep out.  '
                              'For method=progress it is the number of steps in the training.'))
    parser.add_argument('--dataset', dest='dataset', choices=['HG', 'HT', 'all'], default='all',
                        help='The dataset to use, HG, HT, or all.')

    parser.add_argument('--dual', dest='dual', action='store_true',
                        help='Will build separate models for HG and HT before combining them, defaults to --no-dual')
    parser.add_argument('--no-dual', dest='dual', action='store_false')
    parser.set_defaults(dual=False)
    parser.add_argument('-dx', '--dual_export', dest='dual_export', action='store_true',
                        help='Sets --dual to true and exports separate models for HG and HT')
    parser.set_defaults(dual_export=False)

    parser.add_argument('--ridge', dest='ridge', action='store_true',
                        help='Will choose ridge regression over linear regression.')
    parser.set_defaults(ridge=False)

    parser.add_argument('-v', '--version', dest='version', action='store_true',
                        help='Prints version and exits.')

    parser.add_argument('--debug',
                        help="Print only debugging statements",
                        action="store_const", dest="loglevel", const=logging.DEBUG,
                        default=logging.WARNING)
    parser.add_argument('--verbose',
                        help="Massive amount of outputs",
                        action="store_const", dest="loglevel", const=logging.INFO)

    return parser.parse_known_args()


def get_limits(params):
    return LIMITS if params.clean else {}

def get_normalize(params):
    return FEATURES if params.normalize else ()


def method_fcv(params):
    test_data, learn_res = file_cross_val(params.dataset,
                                          k=params.k,
                                          degree=params.degree,
                                          limits=get_limits(params),
                                          normalize=get_normalize(params),
                                          dual_model=params.dual_model,
                                          ridge=params.ridge)

    logging.info("\n\n\n\n################ SUMMARY ###############")
    logging.info("Cross validations performed: %d" % len(test_data))

    test_data.sort(key=lambda result: result[2][0])
    training_scores = zip(*(zip(*test_data)[2]))[0]

    logging.info("\nR^2 training score:")
    logging.info("\t- Average: \t%.6f" % np.average(training_scores))
    logging.info("\t- Median:  \t%.6f" % np.median(training_scores))
    logging.info("\t- Std dev: \t%.6f" % np.std(training_scores))
    logging.info("\t- Worst:   \t%.6f  (obtained when testing on: [%s])" %
                 (training_scores[0], ", ".join(test_data[0][1])))

    test_data.sort(key=lambda result: min(result[2][1:]))
    test_scores = [result[1:] for result in zip(*test_data)[2]]
    all_test_scores = reduce(lambda x,y: x+y, test_scores)

    print("\nR^2 test score:")
    print("\t- Average: \t%.6f" % np.average(all_test_scores))
    print("\t- Median:  \t%.6f" % np.median(all_test_scores))
    print("\t- Std dev: \t%.6f" % np.std(all_test_scores))
    print("\t- Worst:   \t%.6f (obtained when testing on: %s)" %
          (min(test_scores[0]), ", ".join(test_data[0][1])))


    best = None
    for case in learn_res:
        for res in case:
            if best is None or res.r2_test > best.r2_test:
                best = res
    print('R^2 score: %.3f' % best.r2_test)
    print('%s' % best.polynomial)
    return best


def method_icv(params):
    for input_file in params.dataset:
        logging.info("\nDoing individual cross validation for %s" % input_file)
        scores = individual_cross_validation(input_file,
                                             k=params.k,
                                             degree=params.degree,
                                             limits=get_limits(params),
                                             normalize=get_normalize(params),
                                             ridge=params.ridge)
        fname = path_split(input_file)
        print("\nFile:     %s" % fname[1])
        print("Accuracy: %0.4f (+/- %0.4f)" % (scores.mean(), scores.std() * 2))
        print("Scores:   %s" % ", ".join(['%.4f' % s for s in scores]))



def method_simple(params):
    for input_file in params.dataset:
        logging.info("\nDoing regression for %s" % input_file)
        try:
            full_model= train_and_evaluate_single_file(input_file,
                                                       training_fraction=params.training_fraction,
                                                       degree=params.degree,
                                                       limits=get_limits(params),
                                                       normalize=get_normalize(params),
                                                       ridge=params.ridge)
        except ValueError as err:
            logging.ERROR('Could not train on file %s: %s' % (input_file, err))
            return
        visualize(*full_model)
    plt.show()


def method_pca(params):
    plt.title('Turbine polynomial PCA')
    i = 0
    N = len(params.dataset)
    for input_file in params.dataset:
        fname = path_split(input_file)
        i = i + 1
        if N > 1:
            plt.subplot(math.ceil(N/2.0), 2, i)
        plt.ylabel(fname[1])
        X_1, X_2, y = pca(input_file,
                          limits=get_limits(params),
                          normalize=get_normalize(params))
        ### Plot the 2 dimensions with y as color of circle
        cmap = sns.cubehelix_palette(as_cmap=True)
        plt.scatter(X_1, X_2, c=y, cmap=cmap)
    plt.show()


def _plot_reg(params, data, i):
    plt.subplot(len(params.dataset), 2, (2*i)+2)
    plt.ylim([0, 20*1000])
    p_speed, = plt.plot(data['TIME'],
                        data['SPEED'],
                        'o', markersize=2, label='SPEED')
    p_dtemp, = plt.plot(data['TIME'],
                        data['DISCHARGE_TEMP'] * 10,
                        'o', markersize=2, label='DISCHARGE_TEMP')
    p_dpres, = plt.plot(data['TIME'],
                        data['DISCHARGE_PRES'] * 1000,
                        'o', markersize=2, label='DISCHARGE_PRES')
    p_atemp, = plt.plot(data['TIME'],
                        data['AIR_IN_TEMP'] * 10 * 100,
                        'o', markersize=2, label='AIR_IN_TEMP')
    p_apres, = plt.plot(data['TIME'],
                        data['AIR_IN_PRES'] * 1000 * 10,
                        'o', markersize=2, label='AIR_IN_PRES')
    plt.legend(handles=[p_speed, p_dtemp, p_dpres,
                        p_atemp, p_apres])


def method_reg(params):
    plt.title('Turbine polynomial')
    N = len(params.dataset)
    for i in range(N):
        input_file = params.dataset[i]
        fname = path_split(input_file)
        plt.subplot(len(params.dataset), 2, (2*i)+1)
        plt.ylabel(fname[1])
        logging.info("\nDoing regression for %s" % input_file)
        data, full_model, reg_res = regression(input_file,
                                               training_fraction=params.training_fraction,
                                               degree=params.degree,
                                               limits=get_limits(params),
                                               normalize=get_normalize(params))
        visualize(*full_model)
        _plot_reg(params, data, i)
    plt.show()


def method_export(params):
    TYPES = ('',)
    dual = params.dual_model
    if params.dual_export:
        TYPES = ('HG', 'HT')
        dual = False # not needed when we run separate trainings

    for TY in TYPES:
        dataset = [fname for fname in params.dataset if TY in fname]
        _, _, reg_res = joined_regression(dataset,
                                          training_fraction=params.training_fraction,
                                          degree=params.degree,
                                          dual_model=dual,
                                          limits=get_limits(params),
                                          normalize=get_normalize(params),
                                          purge=params.purge,
                                          ridge=params.ridge)
        if len(TYPES) > 1:
            print('\nPolynomial for type %s:' % TY)
        print('R^2 score: %.4f' % reg_res.r2_test)
        print('%s' % reg_res.polynomial)


def method_progress(params):
    plt.title('Turbine polynomial')

    dataset = [params.dataset[0]]
    if len(params.dataset) > 1:
        # TODO add support for more files with stddev
        logging.error('Warning: Progress currently supports one file only')
        logging.error('Warning: Using %s' % dataset)
    N = len(dataset)
    progress = []
    for i in range(N):
        input_file = dataset[i]
        fname = path_split(input_file)
        plt.ylabel(fname[1])
        logging.info("\nDoing regression for %s" % input_file)
        progress = compute_learning_progress(input_file,
                                             steps=params.k,
                                             degree=params.degree,
                                             limits=get_limits(params),
                                             normalize=get_normalize(params))
    r2train  = [x.r2_train for x in progress]
    r2test   = [x.r2_test for x in progress]
    rmstrain = [x.rms_train for x in progress]
    rmstest  = [x.rms_test for x in progress]

    pp = lambda lst: " ".join(map(lambda x: "%.3f" % x, lst))
    logging.info('R^2 train:  %s' % pp(r2train))
    logging.info('R^2 test:   %s' % pp(r2test))
    logging.info('RMS train:  %s' % pp(rmstrain))
    logging.info('RMS test:   %s' % pp(rmstest))

    plt.subplot(2, 1, 1)
    plt.ylabel('R^2')
    legend_r2train, = plt.plot(r2train, label='R^2 training')
    legend_r2test,  = plt.plot(r2test,  label='R^2 test')
    plt.legend(handles=[legend_r2train, legend_r2test])

    plt.subplot(2, 1, 2)
    plt.ylabel('RMS')
    legend_rmstrain, = plt.plot(rmstrain, label='RMS training')
    legend_rmstest,  = plt.plot(rmstest,  label='RMS test')
    plt.legend(handles=[legend_rmstrain, legend_rmstest])
    plt.show()



def main(args, dataset):
    dual = args.dual
    if not dual and args.dual_export:
        dual = True
        logging.warn('--dual_export sets --dual')
    params = LearningParameter(degree=args.degree,
                               k=args.k,
                               training_fraction=args.training_fraction,
                               dataset=dataset,
                               clean=args.clean,
                               normalize=args.normalize,
                               purge=args.purge,
                               dual_model=dual,
                               dual_export=args.dual_export,
                               ridge=args.ridge)
    print_params(args, dataset)
    methods = {
        'fcv'    : method_fcv,
        'icv'    : method_icv,
        'simple' : method_simple,
        'pca'    : method_pca,
        'export' : method_export,
        'progress' : method_progress,
        'prediction' : method_prediction,
        'reg'    : method_reg
    }
    if params.clean:
        logging.info('Cleaning data:\n\t%s' % '\n\t'.join(map(str, [(k, LIMITS[k]) for k in LIMITS])))
    fn = methods[args.method]
    fn(params)


def print_params(args, dataset):
    logging.info('Arguments:   %s' % args)
    logging.info('\nSettings:')
    logging.info('\tDataset:     %s' % dataset)
    logging.info('\tMethod:      %s' % args.method)
    logging.info('\tdual:        %s' % ('Dual model' if args.dual else 'Monomodel'))
    logging.info('\tdual_export: %s' % ('Dual export' if args.dual_export else 'No'))
    logging.info('\tridge:       %s' % ('Ridge regression' if args.ridge else 'Linear regression'))
    logging.info('\tdegree:      %s' % args.degree)
    logging.info('\tk-fold cv:   k=%s' % args.k)
    logging.info('\ttraining_q:  %s' % args.training_fraction)
    logging.info('\tcleaning:    %s' % ('Cleaning data' if args.clean else 'No cleaning'))
    logging.info('\tnormalizing: %s' % ('Normalizing data' if args.normalize else 'No normalizing'))
    logging.info('-------------------\n\n')


def filter_dataset(dataset, filter):
    """filter in (None, 'HG', HT')"""
    if filter not in (None, '', False, 'all', 'HG', 'HT'):
        raise KeyError('Unknown filter "%s"' % filter)
    if not filter or filter == 'all':
        return dataset
    return [fname for fname in dataset if filter in fname]

if __name__ == "__main__":
    args, dataset = create_argparse()
    dual = args.dual or args.dual_export
    if dual and args.dataset in ['HG', 'HT']:
        exit('Cannot use both --dual/--dual_export and --dataset')
    if args.version:
        print('turbinelearn version %s' % TURBINELEARN_VERSION)
        exit(0)

    # Set logging to have no prefix and to use arg_parse's loglevel
    logging.basicConfig(format='%(message)s',
                        level=args.loglevel)

    dataset = filter_dataset(dataset, args.dataset)
    if not dataset:
        exit('Usage: turbine --method=pca data/LOCO*csv')
    try:
        main(args, dataset)
    except KeyboardInterrupt:
        logging.info('\n\nUser aborted.\n')
